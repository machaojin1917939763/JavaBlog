---
title: 美团一面
order: 2
category:
  - 12306
tag:
  - 12306
---

## 项目

## 线程池了解哪些参数（JAVA相关的问题）

线程池一共有七个参数，分别是核心线程数、最大线程数、非核心线程的存活时间、时间单位、阻塞队列、线程工厂、拒绝策略

核心线程数：一般任务提交以后，首先判断阻塞队列满了没有，如果没满，然后再判断当前运行的线程是否小于核心线程，如果小于，就交给核心线程执行

救急线程数：救急线程等于最大线程数减去核心线程数，救急线程是用来救急的，也就是当核心线程全部用完以后，并且阻塞队列满了以后，就会启动救急线程来执行任务

存活时间：当救急线程处理完任务以后，在指定的时间单位以内没有再接收到新的任务，就会消亡

线程工厂：在初始化线程池的时候为线程添加特性，比如设置线程名字、设置是否为守护线程等等

阻塞队列：阻塞队列主要有两大类，一类有有界队列、另外一类是无解队列，有界队列主要是ArraysListBlockingQueue，无界队列主要是LinkedListBlockingQueue，并且默认的大小是Integer.MAX_VALUE，使用Excutor创建出来的默认都是无界队列，所以建议不用无界队列，会导致系统资源耗尽，还有一个优先级队列，PriorityBlockingQueue，每一个线程都有一个权重

拒绝策略：线程池的拒绝一共有四种，分别是抛异常、直接丢弃、线程自己执行、去掉阻塞队列中最久未执行的线程，默认的拒绝策略是抛异常，拒绝策略是在阻塞队列满了以后，并且救急线程也满了，就会走阻塞队列

## 消息队列满了会怎么样

消息队列满了的原因主要是生成者生产太快，导致消费者消费不过来。现在主要解决的问题是，需要增加消费者的数量，先停掉现有的消费者，然后征用十台服务器，临时搭建出十个队列，对应十个消费者，然后写代码将第一个满的队列的消息分发到这十个队列中，然后启动消费者进行消费，等待消费完以后，再恢复原来的模式，或者做出对应的调整

## 同步异步，阻塞非阻塞

### 1. 同步 (Synchronous) vs. 异步 (Asynchronous):

- **同步 (Synchronous)**:
  - 在同步操作中，一个任务必须完成后，下一个任务才能开始。
  - 例如，当你在浏览器中打开一个网页，浏览器可能需要等待服务器的响应。在此期间，你不能与该特定的浏览器窗口进行任何交互，直到页面加载完成。这是一个同步操作的例子。

- **异步 (Asynchronous)**:
  - 在异步操作中，一个任务的开始不依赖于另一个任务的完成。
  - 例如，当你在一个现代的web应用中点击一个按钮请求数据，应用可能会立即响应并允许你进行其他操作，同时在后台等待数据。当数据准备好时，应用会更新相应的部分。这是一个异步操作的例子。

### 2. 阻塞 (Blocking) vs. 非阻塞 (Non-blocking):

- **阻塞 (Blocking)**:
  - 在阻塞操作中，执行某个操作会导致程序停止，直到该操作完成。
  - 例如，当一个程序读取一个大文件时，如果它是阻塞的，那么程序在文件读取完成之前不会执行任何其他操作。

- **非阻塞 (Non-blocking)**:
  - 在非阻塞操作中，即使某个操作尚未完成，程序也不会停止。
  - 例如，当一个程序尝试读取一个网络套接字时，如果它是非阻塞的，那么即使数据尚未到达，程序也会继续执行其他操作。

### 关系与区别:

- 同步/异步通常描述的是操作的完成情况：是否需要等待操作完成，或者是否可以在操作完成后再处理结果。
- 阻塞/非阻塞描述的是程序在等待结果时的状态：是否继续执行其他操作，或者是否停止并等待。

## IO多路复用的几种方式

IO多路复用是一种允许单个线程监视多个文件描述符（通常是网络套接字）的技术，以检查它们是否准备好进行读或写操作。这种技术可以有效地管理大量的并发连接，而不需要为每个连接使用多个线程或进程。以下是几种常见的IO多路复用技术：

1. **select**:
   - 是最古老的IO多路复用解决方案。
   - 它允许应用程序监视多个文件描述符，等待一个或多个描述符准备好进行IO操作。
   - 优点：跨平台，几乎在所有系统上都可用。
   - 缺点：它有一个固定的大小限制，通常是FD_SETSIZE（通常为1024），这限制了它可以监视的文件描述符的数量。

2. **poll**:
   - 与select类似，但没有固定的大小限制。
   - 使用一个链表来跟踪需要监视的文件描述符，因此不受FD_SETSIZE的限制。
   - 优点：没有文件描述符的数量限制。
   - 缺点：当文件描述符的数量增加时，效率可能会降低，因为它需要遍历整个链表。

3. **epoll (Linux特有)**:
   - 是Linux特有的IO多路复用解决方案，专为大量并发连接设计。
   - 使用事件驱动方式，只返回已经准备好的文件描述符。
   - 优点：非常高效，尤其是在大量并发连接的情况下。
   - 缺点：仅在Linux上可用。

4. **kqueue (BSD系统，如FreeBSD, macOS)**:
   - 是BSD系统的IO多路复用解决方案。
   - 与epoll类似，也是事件驱动的。
   - 优点：高效，适用于大量并发连接。
   - 缺点：仅在BSD系统上可用。

5. **IOCP (Windows特有)**:
   - Input/Output Completion Ports，是Windows系统的IO多路复用和异步IO解决方案。
   - 与epoll和kqueue类似，也是事件驱动的。
   - 优点：高效，适用于大量并发连接。
   - 缺点：仅在Windows上可用。

在选择IO多路复用的技术时，需要考虑目标平台、预期的并发连接数量以及其他特定需求。例如，如果你正在开发一个跨平台的应用程序，可能需要使用select或poll。但如果你正在为Linux开发一个高并发的服务器，那么epoll可能是最佳选择。

## mysql了解哪些锁

1. 数据库锁：锁住整个数据库
2. 元数据锁：锁住表的元数据，也就是禁止DDL语句的执行
3. 表锁：锁住整张表
4. 意向锁：在表的层面进行加锁，用于添加表锁时的检验
5. 行锁：锁住一行数据
6. 记录锁：锁住一条记录
7. 间隙锁：锁住一段记录，一个前开后开的区间
8. 临键锁：锁住一段记录，加上一条记录，前开后闭的区间
9. 共享锁：锁可重复加
10. 独占锁：锁锁互斥
11. 读锁：和共享锁类似
12. 写锁：和独占锁类似
13. 自增锁：保证多个事务的自增是唯一的

## 意向锁是干嘛的

是用来降低加锁时间的，如果一张表中有一个行锁，但是我的另外一个事务要过来加表锁，但是那个事务不知道表里面是否有行锁，就会一条记录一条记录的进行扫描，需要把全表一起扫一遍，但是有意向锁以后，当这张表中加了行锁以后，再加上一个意向锁，当另外一个事务来加表锁时，就会检查是否有表锁，不会再一行一行的检查，降低了加锁的时间

锁升级的中间步骤，当锁从共享锁升级成为排他锁时，会先获取意向排他锁，然后再升级共享锁，避免锁模式的冲突

## 给了几个SQL语句，问会加哪些锁

## 元数据锁和意向锁区别

元数据锁时锁住表的DDL语句的，当事务执行时，会默认添加元数据锁，禁止修改表结构，元数据锁会阻塞所有的DML语句，而意向锁有两种分类，一种是意向排他锁，一种是意向共享锁

元数据锁（Metadata Lock，简称MDL）和意向锁（Intention Locks）都是MySQL中用于确保数据完整性和并发控制的锁机制，但它们的目的、作用范围和应用场景有所不同。以下是它们之间的主要区别：

### 元数据锁 (Metadata Lock, MDL)：

1. **目的**：MDL的主要目的是防止多个会话同时更改数据库对象的结构（例如，通过`ALTER TABLE`命令）。它确保在一个会话修改表结构时，其他会话不能访问该表。

2. **作用范围**：MDL作用于数据库的元数据，例如表的结构或存储过程的定义。

3. **类型**：MDL可以是共享的或排他的。共享MDL允许多个会话读取表，但不允许修改它。排他MDL允许会话修改表，并阻止其他会话访问它。

4. **生命周期**：MDL通常在SQL语句开始执行时获得，并在语句完成时释放。

### 意向锁 (Intention Locks)：

1. **目的**：意向锁的主要目的是提高InnoDB存储引擎的并发性能。它们表示事务打算在某个表的行上获得更具体的锁（如共享锁或排他锁）。

2. **作用范围**：意向锁作用于表的行。它们不直接锁定行，而是表示事务打算在这些行上获得锁。

3. **类型**：有两种主要的意向锁：意向共享锁（IS锁）和意向排他锁（IX锁）。

4. **生命周期**：意向锁通常在事务开始时获得，并在事务结束时释放。

### 总结：

- 元数据锁主要关注数据库对象的结构和定义，确保在修改这些对象时不会有并发访问。
- 意向锁则关注表的行，并表示事务打算在这些行上获得何种类型的锁。
  

尽管它们的目的和作用范围不同，但它们都是为了确保数据的完整性和并发性而存在的。

## redis主从同步

Redis的主从同步（Master-Slave Replication）是其核心功能之一，允许一个Redis服务器（称为主服务器或Master）的数据被复制到一个或多个Redis服务器（称为从服务器或Slave）。这种同步机制有多种用途，如数据冗余、数据备份、高可用性和负载均衡。

以下是Redis主从同步的基本概念和工作原理：

### 1. **设置**:
要设置从服务器，只需在从服务器上执行以下命令：
```
SLAVEOF <master-ip> <master-port>
```
这会指示从服务器连接到指定的主服务器，并开始同步数据。

### 2. **全量复制**:
当从服务器首次连接到主服务器时，主服务器会执行一个`BGSAVE`操作，创建一个数据快照并将其发送到从服务器。从服务器接收此数据并加载到其数据集中。

### 3. **增量复制**:
全量复制完成后，主服务器会将所有新的、修改的或删除的数据命令实时地发送到从服务器，确保从服务器的数据与主服务器保持同步。

### 4. **断线重连**:
如果从服务器与主服务器的连接断开，从服务器会尝试重新连接。一旦重新连接，通常会进行部分重同步，即只同步断开连接期间在主服务器上发生的更改。如果部分重同步不可能（例如，缺少必要的日志），则会再次进行全量复制。

### 5. **只读从服务器**:
默认情况下，从服务器是只读的。这意味着客户端不能在从服务器上执行写操作。这是为了保持数据的一致性。但是，可以通过配置更改此行为。

### 6. **用途**:
- **数据冗余**：多个服务器拥有相同的数据副本，提高数据的可靠性。
- **数据备份**：从服务器可以定期创建数据快照，作为备份。
- **负载均衡**：读操作可以分发到一个或多个从服务器，从而分担主服务器的负载。
- **高可用性**：如果主服务器出现故障，其中一个从服务器可以被提升为新的主服务器。

### 7. **主从链**:
可以配置多级主从复制，即一个从服务器也可以作为其他从服务器的主服务器。但是，这种配置可能会增加复制延迟。

### 8. **主从切换**:
在某些情况下，如主服务器故障，从服务器可以被提升为主服务器。这通常与哨兵（Sentinel）系统或Redis集群一起使用，以自动处理故障转移。

总的来说，Redis的主从同步是一个强大的功能，可以满足多种数据管理和扩展需求。

## 断点续传时主从同步有什么机制

在Redis中，断点续传是指当主从同步过程中出现中断，从服务器（Slave）在重新连接主服务器（Master）后，尝试从断开的地方继续同步，而不是重新开始全量复制。这种机制可以节省带宽和时间，特别是当数据集很大时。

以下是Redis断点续传的主要机制：

### 1. **复制偏移量和复制积压缓冲区**:

- 主服务器和从服务器都维护一个复制偏移量，表示它们在复制流中的位置。
  
- 主服务器还维护一个称为“复制积压缓冲区”（Replication Backlog）的缓冲区。这是一个固定大小的循环缓冲区，用于存储最近的写命令。当从服务器请求增量复制时，主服务器可以使用此缓冲区提供所需的数据。

### 2. **部分重同步（PSYNC）**:

- 当从服务器与主服务器断开连接并重新连接时，它会尝试执行部分重同步（PSYNC）。从服务器会发送其已知的复制偏移量和复制ID给主服务器。

- 如果主服务器的复制积压缓冲区中包含从服务器所需的所有数据（即数据没有被覆盖），主服务器会接受部分重同步请求，并只发送从服务器缺失的数据。

- 如果主服务器的复制积压缓冲区中不包含从服务器所需的所有数据，那么将进行全量复制（即使用`SYNC`命令）。

### 3. **复制ID**:

- 为了支持断点续传，Redis引入了复制ID的概念。每次全量复制时，都会生成一个新的复制ID。

- 主服务器和从服务器都有两个复制ID：当前复制ID和上一个复制ID。这允许从服务器在短时间内重新连接并尝试部分重同步，即使在此期间发生了全量复制。

### 4. **配置和限制**:

- 复制积压缓冲区的大小可以通过`repl-backlog-size`配置选项进行设置。如果数据集很大或网络连接经常中断，可能需要增加此值。

- `repl-backlog-ttl`配置选项定义了在没有从服务器连接的情况下，主服务器应保持复制积压缓冲区的时间。

总的来说，Redis的断点续传机制通过使用复制偏移量、复制积压缓冲区和复制ID，允许从服务器在连接中断后从中断点继续同步，从而提高了复制的效率和鲁棒性。

## 同步的缓冲区是什么样的结构

在Redis中，为了支持断点续传的同步机制，主服务器维护了一个名为“复制积压缓冲区”（Replication Backlog）的结构。这个复制积压缓冲区是一个固定大小的循环缓冲区，用于存储最近的写命令。以下是关于这个缓冲区的一些详细信息：

1. **循环缓冲区**：复制积压缓冲区是一个循环（或环形）缓冲区。当它被填满时，新的数据会覆盖最旧的数据。这意味着它始终包含最近的N个字节的数据，其中N是缓冲区的大小。

2. **固定大小**：缓冲区的大小是固定的，可以通过`repl-backlog-size`配置选项进行设置。默认值通常为1MB，但可以根据需要进行调整。

3. **偏移量**：为了知道缓冲区中的数据对应于复制流中的哪个位置，Redis维护了一个全局的复制偏移量。每当数据被添加到缓冲区时，此偏移量都会增加。

4. **用途**：当一个从服务器尝试进行部分重同步时，它会告诉主服务器它上次同步的位置（即其已知的复制偏移量）。主服务器会查看其复制积压缓冲区，确定是否可以从中提供所需的数据。如果可以，主服务器将从缓冲区发送数据；如果不可以（例如，所需的数据已被覆盖），则会进行全量复制。

5. **生命周期**：即使没有从服务器连接，主服务器也会维护复制积压缓冲区。但是，如果在一段时间（由`repl-backlog-ttl`配置选项定义）内没有从服务器连接，主服务器可能会释放这个缓冲区以节省内存。当新的从服务器连接时，缓冲区会被重新创建。

总的来说，复制积压缓冲区是Redis断点续传同步机制的核心组件，它允许主服务器存储最近的写命令，以便在从服务器重新连接后进行部分重同步。

## 如果新的写命令覆盖了旧命令会怎么样

在Redis的复制积压缓冲区（Replication Backlog）中，当新的写命令到来并且缓冲区已满时，新的写命令会覆盖最旧的命令。这是因为复制积压缓冲区是一个循环（或环形）缓冲区。

如果新的写命令覆盖了旧命令，以下是可能的影响：

1. **部分重同步的影响**：当一个从服务器尝试进行部分重同步，并且它需要的数据已经从复制积压缓冲区中被覆盖时，部分重同步将失败。在这种情况下，主服务器和从服务器将执行全量复制（即从头开始同步所有数据）。

2. **带宽和时间的消耗**：全量复制通常比部分重同步更耗费带宽和时间，特别是当数据集很大时。这可能会导致从服务器在复制过程中花费更多的时间处于不同步状态。

3. **内存和CPU的消耗**：全量复制需要主服务器执行`BGSAVE`操作（除非RDB快照已经可用），这可能会增加CPU和磁盘I/O的使用。同时，从服务器需要加载接收到的RDB快照，这也会增加其CPU和内存的使用。

为了减少因复制积压缓冲区数据被覆盖而导致的全量复制的次数，可以考虑以下策略：

1. **增加复制积压缓冲区的大小**：通过调整`repl-backlog-size`配置选项，可以为复制积压缓冲区分配更多的内存，从而减少数据被覆盖的可能性。

2. **监控网络连接**：确保主服务器和从服务器之间的网络连接是稳定的，以减少断开连接和重新连接的次数。

3. **监控复制延迟**：可以使用`INFO REPLICATION`命令监控复制的健康状况和延迟，以及从服务器的偏移量与主服务器的差异。

总之，当新的写命令在复制积压缓冲区中覆盖旧命令时，可能会导致部分重同步失败，从而需要进行全量复制。为了避免这种情况，可以考虑调整配置和监控复制的健康状况。

## TCP粘包和拆包

TCP（传输控制协议）是一个面向连接的、可靠的、字节流的传输层通信协议。由于其设计为传输连续的字节流，而不是消息或数据包，因此在TCP通信中可能会遇到所谓的“粘包”和“拆包”问题。

### 1. **粘包 (Sticking Packets)**:
当多个发送端的数据包在接收端被接收为一个数据包时，称为粘包。例如，应用程序发送了两个数据包A和B，但接收端接收到的可能是一个包含A和B的数据包。

### 2. **拆包 (Splitting Packets)**:
当一个发送端的数据包在接收端被拆分为多个数据包时，称为拆包。例如，应用程序发送了一个大的数据包C，但接收端可能会分多次接收这个数据包的内容。

### 为什么会发生粘包和拆包？

1. **TCP是一个字节流协议**：TCP不保留消息或数据包的边界，它只关心字节序列。因此，连续发送的多个消息可能会被接收为一个消息，或者一个大消息可能会被拆分为多个小消息。

2. **网络拥塞**：由于网络拥塞或其他原因，发送的数据可能会在传输过程中被暂存，然后一次性发送，导致多个消息被合并为一个。

3. **接收缓冲区的大小**：如果接收缓冲区不足以容纳发送的所有数据，那么数据可能会被拆分为多个部分。

### 如何处理粘包和拆包？

1. **固定长度的消息**：每个消息都有固定的长度，这样接收端知道每次应该读取多少字节。

2. **分隔符**：在每个消息的末尾添加一个特殊的分隔符，如换行符。接收端可以根据这个分隔符来确定消息的边界。

3. **长度前缀**：在每个消息前发送一个头部，指示消息的长度。接收端首先读取这个头部，然后根据头部中的长度值读取相应的字节数。

4. **应用层协议**：使用像WebSocket、HTTP/2这样的应用层协议，它们在协议层面处理消息的边界。

总的来说，TCP粘包和拆包是由于TCP的设计和网络的特性导致的。为了在应用层正确地处理消息，开发者需要实现一些策略或机制来确定消息的边界。

## TCP拥塞控制和流量控制

TCP（传输控制协议）是为了提供可靠的数据传输而设计的。为了确保网络的稳定性和效率，TCP实现了拥塞控制和流量控制机制。尽管这两种控制机制都涉及调整数据的发送速率，但它们的目的和工作方式是不同的。

### 1. **TCP流量控制**:

流量控制是为了防止发送方发送速度过快，导致接收方来不及处理，从而溢出其接收缓冲区。

- **滑动窗口**：TCP使用滑动窗口机制来实现流量控制。接收方通过TCP头部的窗口大小字段告诉发送方它的接收窗口大小，即它还能接收多少数据而不会溢出。
  
- **停止并等待**：最简单的流量控制方法是接收方每接收一个数据包就发送一个确认。发送方在发送一个数据包后必须等待确认才能发送下一个数据包。

- **接收窗口调整**：如果接收方的应用程序暂时不读取数据，接收窗口可能会减小，甚至变为零。这会告诉发送方减慢发送速率或停止发送。

### 2. **TCP拥塞控制**:

拥塞控制是为了避免过多的数据注入到网络中，从而导致网络拥塞。它是基于网络的状态，而不是接收方的状态。

- **慢启动**：当开始传输或经历了丢包时，TCP不会立即发送大量数据，而是从小的拥塞窗口开始，并在每次接收到确认时将其加倍，直到达到一个阈值。

- **拥塞避免**：当拥塞窗口达到阈值后，TCP会进入拥塞避免模式，窗口大小每次增加一个最大段大小。

- **快速重传和快速恢复**：如果发送方检测到三个重复的ACK，它会立即重新发送未确认的数据包（而不是等待超时），并减小拥塞窗口。

- **拥塞窗口调整**：如果检测到网络拥塞（例如，由于超时或重复的ACK），拥塞窗口会被减小。

### 总结：

- **流量控制**是基于接收方的能力和状态，确保发送方不会溢出接收方的缓冲区。
  
- **拥塞控制**是基于网络的状态，确保不会注入过多的数据到网络中，从而导致网络拥塞。

这两种控制机制确保了TCP的可靠性和网络的稳定性。

## Linux进程间通信方式

在Linux系统中，进程间通信（Inter-Process Communication, IPC）是一个核心概念，允许进程之间交换数据和信号。以下是Linux中常见的进程间通信方式：

1. **管道 (Pipe)**:
   - 通常用于父子进程间的通信。
   - 数据在管道中是有序的，可以被视为一个先进先出（FIFO）的队列。
   - 通常与shell命令中的`|`符号一起使用。

2. **命名管道 (Named Pipe 或 FIFO)**:
   - 类似于管道，但它有一个文件名与之关联，允许不相关的进程通信。
   - 使用`mkfifo`命令创建。

3. **信号 (Signal)**:
   - 用于通知进程某个事件已经发生。
   - 例如，`SIGKILL`和`SIGTERM`信号用于终止进程。

4. **消息队列 (Message Queues)**:
   - 允许进程发送和接收消息。
   - 消息是有序的，并且可以按优先级进行排序。

5. **共享内存 (Shared Memory)**:
   - 允许多个进程访问同一块内存区域。
   - 是一种非常快速的IPC方式，但需要同步机制（如信号量）来避免竞态条件。

6. **信号量 (Semaphores)**:
   - 用于同步进程的执行，特别是在访问共享资源时。
   - 可以是二进制的（即锁）或可以有多个值。

7. **套接字 (Sockets)**:
   - 用于本地或网络间的进程通信。
   - 支持TCP、UDP和其他协议。
   - 可以用于不同机器之间的进程通信。

8. **文件和文件锁**:
   - 进程可以通过读写文件进行通信。
   - 使用文件锁（例如，`flock`）可以同步对文件的访问。

9. **内存映射 (Memory-mapped files)**:
   - 允许文件或文件的一部分被映射到进程的地址空间。
   - 可以用于文件I/O，也可以用作共享内存。

10. **Unix域套接字 (Unix Domain Sockets)**:
   - 类似于网络套接字，但仅用于同一机器上的进程间通信。
   - 通常比网络套接字更快，因为它们不涉及网络堆栈。

这些IPC机制为Linux提供了强大的灵活性，允许开发者根据需要选择最合适的通信方式。